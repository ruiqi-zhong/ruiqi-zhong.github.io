<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Ruiqi Zhong</title>
  
  <meta name="author" content="Ruiqi Zhong">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Ruiqi Zhong</name>
              </p>
              <p>
                  I am a final-year PhD student in the UC Berkeley EECS department. I was previously a part-time research scientist at <a href="https://www.anthropic.com">Anthropic</a>.
                  I am co-advised by  Prof. <a href="https://www.stat.berkeley.edu/~jsteinhardt/">Jacob Steinhardt</a> and Prof.
                  <a href="https://people.eecs.berkeley.edu/~klein/">Dan Klein</a>.
              </p>
              <p>
                  Before coming to Berkeley, I finished my undergrad at Columbia
                  University, where I worked with Prof.
                  <a href="http://www.cs.columbia.edu/~kathy/">Kathleen McKeown</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:ruiqi-zhong@berkeley.edu">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=GskOShAAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/ZhongRuiqi">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/ruiqi-zhong">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/photo.jpeg"><img
                      style="width:80%;max-width:80%" alt="profile photo" src="images/1011_profile.JPG" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <heading>Research Overview</heading>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <p>
                  I use AI to explain <a href="https://arxiv.org/abs/2406.04604">programs</a>, <a href="https://arxiv.org/abs/2307.08678">models</a>, and <a href="https://arxiv.org/abs/2409.08466">datasets</a>. My goal is to empower humans to achieve what they cannot achieve on their own. See presentation slides <a href="https://github.com/ruiqi-zhong/presentations/blob/main/scalable-oversight.pdf">here</a> and my talk <a href="https://www.youtube.com/watch?v=dHkYN33TtLM">here</a> to get a sense of my research interests.
              </p>
            </td>
          </tr>
        </tbody></table>

        <heading>Blogs</heading>

        <ul>
          <li><a href="https://ruiqizhong.substack.com/p/explaining-ai-alignment-as-an-nlper?sd=pf">Explaining AI Alignment as an NLPer and Why I am Working on It</a>
          </li>
          <li><a href="https://ruiqizhong.substack.com/p/predicting-the-future-to-plan-for?sd=pf">Predicting the Future to Plan for Our Research, Illustrated with Research Stories</a>
          </li>
        </ul>


        <heading>Representative Work</heading>
          <br> <br>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Explaining Datasets in Words: Statistical Models with Natural Language Parameters</papertitle>
              </a>
                <br>
                    <strong>Ruiqi Zhong</strong>,
                Heng Wang,
                Dan Klein,
                Jacob Steinhardt
            <br>
                <i>NeurIPS 2024</i>
            <br>
                <a href="https://arxiv.org/abs/2409.08466">[paper]</a>
                <a href="https://github.com/ruiqi-zhong/nlparam">[code]</a>
                <a href="https://bounded-regret.ghost.io/augmenting-statistical-models-with-natural-language-parameters/">[blog]</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Non-Programmers Can Label Programs Indirectly via Active Examples: A Case Study with Text-to-SQL</papertitle>
              </a>
                <br>
                    <strong>Ruiqi Zhong</strong><sup>*</sup>,
                Charlie Snell<sup>*</sup>,
                Dan Klein,
                Jason Eisner
            <br>
                <i>EMNLP 2023</i>
            <br>
                <a href="https://arxiv.org/abs/2205.12422">[paper]</a> <a href="https://github.com/ruiqi-zhong/EMNLP23-APEL"> [code] </a> <a href="http://35.225.126.31:4200/v0104_4pm_8">[demo]</a> <a href="https://x.com/ZhongRuiqi/status/1714358706350276665">[tweet]</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Do Models Explain Themselves? Counterfactual Simulatability of Natural Language Explanations</papertitle>
              </a>
                <br>
                Yanda Chen, <strong>Ruiqi Zhong</strong>, Narutatsu Ri, Chen Zhao, He He, Jacob Steinhardt, Zhou Yu, Kathleen McKeown
            <br>
                <i>ICML 2024</i>
            <br>
                <a href="https://arxiv.org/abs/2307.08678">[paper]</a> <a href="https://x.com/yanda_chen_/status/1681412273758408704">[tweet]</a>
            </td>
          </tr>


        </tbody></table>

          <heading>Others</heading>
          
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Language Models Learn to Mislead Humans via RLHF</papertitle>
              </a>
                <br>

                Jiaxin Wen, <strong>Ruiqi Zhong</strong>, Akbir Khan, Ethan Perez, Jacob Steinhardt, Minlie Huang, Samuel R. Boman, He He, Shi Feng
            <br>
                <i>arXiv 2024</i>
            <br>
                <a href="https://arxiv.org/abs/2409.12822">[paper]</a>
                <a href="https://x.com/jiaxinwen22/status/1836932745244582209">[tweet]</a>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Describing Differences in Image Sets with Natural Language</papertitle>
              </a>
                <br>
                Lisa Dunlap<sup>*</sup>, Yuhui Zhang<sup>*</sup>, Xiaohan Wang, <strong>Ruiqi Zhong</strong>, Trevor Darrell<sup>*</sup>, Jacob Steinhardt<sup>*</sup>, Joseph E Gonzalez<sup>*</sup>, Serena Yeung-Levy<sup>*</sup>
            <br>
                <i>CVPR 2024</i>
            <br>
                <a href="https://arxiv.org/abs/2312.02974">[paper]</a><a href="https://understanding-visual-datasets.github.io/VisDiff-website/">[website]</a> <a href="https://x.com/lisabdunlap/status/1732419686837710911">[tweet]</a>
            </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Goal Driven Discovery of Distributional Differences via Language Descriptions</papertitle>
              </a>
                <br>
                    <strong>Ruiqi Zhong</strong>,
                Peter Zhang,
                Steve Li,
                Jinwoo Ahn,
                Dan Klein,
                Jacob Steinhardt
            <br>
                <i>NeurIPS 2023</i>
            <br>
                <a href="https://arxiv.org/abs/2302.14233">[paper]</a>
                <a href="https://github.com/ruiqi-zhong/D5">[code]</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Goal-Driven Explainable Clustering via Language Descriptions</papertitle>
              </a>
                <br>
                Zihan Wang, Jingbo Shang, <strong>Ruiqi Zhong</strong>
            <br>
                <i>EMNLP 2023</i>
            <br>
                <a href="https://arxiv.org/abs/2305.13749">[paper]</a><a href="https://github.com/ZihanWangKi/GoalEx">[code]</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>DS-1000: A Natural and Reliable Benchmark for Data Science Code Generation</papertitle>
              </a>
                <br>
                Yuhang Lai<sup>*</sup>, Chengxi Li<sup>*</sup>, Yiming Wang<sup>*</sup>, Tianyi Zhang<sup>*</sup>, <strong>Ruiqi Zhong<sup>*</sup></strong>, Luke Zettlemoyer, Scott Wen-tau Yih, Daniel Fried, Sida Wang, Tao Yu
            <br>
                <i>ICML 2023</i>
            <br>
                <a href="https://arxiv.org/abs/2211.11501">[paper]</a><a href="https://github.com/HKUNLP/DS-1000">[data]</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>InCoder: A Generative Model for Code Infilling and Synthesis</papertitle>
              </a>
                <br>
Daniel Fried, Armen Aghajanyan, Jessy Lin, Sida Wang, Eric Wallace, Freda Shi, <strong>Ruiqi Zhong</strong>, Wen-tau Yih, Luke Zettlemoyer, Mike Lewis
            <br>
                <i>ICLR 2023</i>
            <br>
                <a href="https://arxiv.org/abs/2110.07814">[paper]</a>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Learning by Distilling Context</papertitle>
              </a>
                <br>
                Charlie Snell, Dan Klein, <strong>Ruiqi Zhong</strong>
            <br>
                <i>arXiv 2022</i>
            <br>
                <a href="https://arxiv.org/abs/2209.15189">[paper]</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Describing Differences between Text Distributions with Natural Language</papertitle>
              </a>
                <br>
                    <strong>Ruiqi Zhong</strong>,
                Charlie Snell,
                Dan Klein,
                Jacob Steinhardt
            <br>
                <i>ICML 2022</i>
            <br>
                <a href="https://arxiv.org/abs/2201.12323">[paper]</a>
                <a href="https://github.com/ruiqi-zhong/DescribeDistributionalDifferences">[code]</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models</papertitle>
              </a>
                <br>
                Tianbao Xie, Chen Henry Wu, Peng Shi, <strong>Ruiqi Zhong</strong>,
                Torsten Scholak, Michihiro Yasunaga, Chien-Sheng Wu, Ming Zhong, Pengcheng Yin, Sida I. Wang, Victor Zhong, Bailin Wang, Chengzu Li, Connor Boyle, Ansong Ni, Ziyu Yao, Dragomir Radev, Caiming Xiong, Lingpeng Kong, Rui Zhang, Noah A. Smith, Luke Zettlemoyer, Tao Yu
            <br>
                <i>EMNLP 2022</i>
            <br>
                <a href="https://arxiv.org/abs/2201.05966">[paper]</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Meta-learning via Language Model In-context
                    Tuning</papertitle>
              </a>
                <br>
                Yanda Chen, <strong>Ruiqi Zhong</strong>, Sheng Zha, George
                Karypis, He He
            <br>
                <i>ACL 2022</i>
            <br>
                <a href="https://arxiv.org/abs/2110.07814">[paper]</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>The Effect of Model Size on Worst-Group Generalization</papertitle>
              </a>
                <br>
                Alan Pham<sup>*</sup>, Eunice Chan<sup>*</sup>, Vikranth Srivatsa<sup>*</sup>, Dhruba Ghosh<sup>*</sup>,
                Yaoqing Yang, Yaodong Yu, <strong>Ruiqi Zhong</strong>, Joseph E.
                Gonzalez, Jacob Steinhardt
            <br>
                <i>NeurIPS 2021 Workshop on Distribution Shifts</i>
            <br>
                <a href="https://arxiv.org/abs/2112.04094">[paper]</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Approximating How Single Head Attention
                    Learns</papertitle>
              </a>
                <br>
                Charlie Snell<sup>*</sup>, <strong>Ruiqi Zhong</strong><sup>*</sup>, Dan Klein, Jacob
                Steinhardt
            <br>
                <i>arXiv 2021</i>
            <br>
    <a href="https://arxiv.org/abs/2103.07601">[paper]</a> <a href="https://github.com/ruiqi-zhong/presentations/blob/main/attentiontraining.pdf">[slides]</a> <a href="https://github.com/Sea-Snell/AttentionDynamics">[code]</a> <a href="https://sea-snell.github.io/AttentionBlogSite/attention/2021/04/01/attention.html">[blog]</a>
            </td>
          </tr>

<tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Adapting Language Models for Zero-shot Learning by Meta-tuning on Dataset and Prompt Collections</papertitle>
              </a>
                <br>
                <strong>Ruiqi Zhong</strong>,
                Kristy Lee<sup>*</sup>, Zheng Zhang<sup>*</sup>,
                Dan Klein
            <br>
                <i>EMNLP 2021, Findings</i>
            <br>
    <a href="https://arxiv.org/abs/2104.04670">[paper]</a><a href="https://github.com/ruiqi-zhong/presentations/blob/main/emnlp2021metatuning.pdf">[slides]</a><a href="https://github.com/ruiqi-zhong/Meta-tuning">[code]</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Are Larger Pretrained Language Models Uniformly Better? Comparing Performance at the Instance Level</papertitle>

                <br>
                <strong>Ruiqi Zhong</strong>,
                Dhruba Ghosh,
                Dan Klein,
                Jacob Steinhardt
                <br>
                <i>ACL 2021, Findings</i>
                <br>
                <a href="https://arxiv.org/abs/2105.06020">[paper]</a> <a href="https://github.com/ruiqi-zhong/presentations/blob/main/acl2021slides.pdf">[slides]</a> <a href="https://github.com/ruiqi-zhong/acl2021-instance-level">[code]</a>

            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Semantic Evaluation for Text-to-SQL with Distilled Test Suites</papertitle>

                    <br>
                    <strong>Ruiqi Zhong</strong>,
                    Tao Yu,
                    Dan Klein
                    <br>
                    <i>EMNLP 2020</i>
                    <br>
                    <a href="https://arxiv.org/abs/2010.02840/">[paper]</a> <a href="https://github.com/ruiqi-zhong/presentations/blob/main/emnlp2020text2sqltestsuite.pdf">[slides]</a> <a href="https://github.com/ruiqi-zhong/TestSuiteEval">[code]</a>

            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Semantic Scaffolds for Pseudocode-to-Code
                    Generation</papertitle>

                <br>
                <strong>Ruiqi Zhong</strong>, Mitchell Stern, Dan Klein
                <br>
                <i>ACL 2020</i>
                <br>
    <a href="https://www.aclweb.org/anthology/2020.acl-main.208/">[paper]</a> <a href="https://github.com/ruiqi-zhong/presentations/blob/main/acl2020semanticscaffold.pdf">[slides]</a> <a href="https://github.com/ruiqi-zhong/SemanticScaffold">[code]</a> <a href="https://youtu.be/sT9Nr9XdfgU">[video]</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Detecting and Reducing Bias in a High Stakes Domain</papertitle>

                    <br>
                <strong>Ruiqi Zhong</strong>, Yanda Chen, Desmond Patton, Charlotte Selous, Kathy
    McKeown
                    <br>
                    <i>EMNLP 2019</i>
                    <br>
    <a href="https://www.aclweb.org/anthology/D19-1483/">[paper]</a> <a href="https://github.com/ruiqi-zhong/presentations/blob/main/emnlp2019debias.pdf">[poster]</a> <a href="https://github.com/David3384/GI_2019">[code]</a>

            </td>
          </tr>

                  <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Fine-grained Sentiment Analysis with Faithful
                    Attention</papertitle>

                    <br>
                <strong>Ruiqi Zhong</strong>, Steven Shao, Kathy McKeown
                    <br>
                    <i>arXiv 2019</i>
                    <br>
    <a href="https://arxiv.org/abs/1908.06870">[paper]</a>`
            </td>
          </tr>

        <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Detecting Gang-involved Escalation on Social
                    Media Using Context</papertitle>

                    <br>
                Serina Chang, <strong>Ruiqi Zhong</strong>, Ethan Adams, Fei-Tzin Lee, Siddharth
                Varia, Desmond Patton, William Frey, Chris Kedzie, Kathy McKeown
                    <br>
                    <i>EMNLP 2018</i>
                    <br>
    <a href="https://aclanthology.org/D18-1005.pdf">[paper]</a> <a href="https://github.com/serinachang5/contextifier">[code]</a>
            </td>
          </tr>

            <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Subspace Embedding and Linear Regression with
                    Orlicz Norm</papertitle>

                    <br>
                Alexandr Andoni, Chengyu Lin, Ying Sheng, Peilin Zhong,
                <strong>Ruiqi Zhong</strong>
                    <br>
                    <i>ICML 2018</i>
                    <br>
    <a href="http://proceedings.mlr.press/v80/andoni18a.html">[paper]</a> <a href="https://vimeo.com/287860768">[video]</a> <a href="https://github.com/ruiqi-zhong/presentations/blob/main/icml2018orliczreg.pdf">[slides]</a>

            </td>
          </tr>

            <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>GAIA - A Multi-media Multi-lingual Knowledge Extraction and Hypothesis Generation System</papertitle>

                    <br>
Tongtao Zhang, Ananya Subburathinam, Ge Shi, Lifu Huang, Di Lu, Xiaoman Pan,
                Manling Li, Boliang Zhang, Qingyun Wang, Spencer Whitehead,
                Heng Ji, Alireza Zareian, Hassan Akbari, Brian Chen,
                <strong>Ruiqi Zhong</strong>, Steven Shao, Emily Allaway, Shih-Fu
                    Chang, Kathleen R. McKeown, Dongyu Li, Xin Huang, Kexuan Sun, Xujun Peng, Ryan Gabbard, Marjorie Freedman, Mayank Kejriwal, Ram Nevatia, Pedro A. Szekely, T. K. Satish Kumar, Ali Sadeghian, Giacomo Bergami, Sourav Dutta, Miguel E. Rodr√≠guez, Daisy Zhe Wang
                    <br>
                    <i>TAC 2018</i>
                    <br>
    <a href="https://openreview.net/forum?id=a9XxVmBDGJ1">[paper]</a>
            </td>
          </tr>

        </tbody></table>

        <heading>External Presentations</heading>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <ul><li>[05/02/2024] At Sasha Rush's group meeting, on explaining datasets with LLMs</li>
                    <li>[04/16/2024] At HKU NLP class, on Scalable Oversight</li>
                    <li>[04/20/2023] At <a href="https://self-supervised.cs.jhu.edu/sp2023/">JHU CS 601</a>, on Scalable Oversight</li> 
                    <li>[04/05/2023] At Anthropic, on Scalable Oversight</li> 
                    <li>[03/30/2023] At <a href="https://www.isi.edu/events/3518/getting-ai-to-do-things-i-cant/">USC NLP Seminar</a>, on Scalable Oversight</li> 
                    <li>[10/27/2022] At NYU, on Scalable Oversight</li>
                    <li>[10/25/2022] At Cornell, Sasha Rush's group meeting, on Scalable Oversight </li>
                    <li>[10/24/2022] At <a href="http://www.cs.columbia.edu/nlp/nlp_seminar.html">Columbia NLP Seminar</a>, on Scalable Oversight </li>
                    <li>[09/07/2022] At Redwood Research, on Scalable Oversight</li>
                    <li>[08/23/2022] At University of Toronto, Roger Grosse's group meeting, on Scalable Oversight</li>
                    <li>[07/28/2022] At Codex Community reading group, on Active Programming by Example with a Natural Language Prior</li>
                    <li>[06/23/2022] At Microsoft Semantic Machines, on Scalable Oversight</li>
                </ul>
            </td>
          </tr>
        </tbody></table>




        <heading>Miscellaneous</heading>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
                <ul>
                    <li>I represented Columbia University in ACM-ICPC and
                        Putnam Math Competition during my Sophormore year
                        (though it seems I was the bottleneck of our teams).</li>
                    <li>I sleep at 11 p.m. and do not respond to later messages. Sometimes, however, I am actually awake; but I pretend not to see them anyways.
</li>
                    <li>My favorite animation character and role model is
                        Wenli Yang in <i>Legend of Galactical Heroes</i>.
</li>

                </ul>

            </td>
          </tr>


        </tbody></table>

        <heading>Awards</heading>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <ul>
                    <li>Berkeley Graduate Student Fellowship</li>
                    <li> Theodore R. Bashkow Award (research), Academic Excellence Award (GPA)</li>
                    <li> CRA Outstanding Undergraduate Research Award
                        Honorable Mention * 2 (2018, 2019) </li>
                    <li> William Lowell Putnam Math Competition top 5% * 3
                        (2015, 2016, 2018) </li>
                </ul>
            </td>
          </tr>
        </tbody></table>

      <heading>Undergrad Advising</heading>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <!-- Yes, I have a serious commitment towards cultivating future
                researchers and practitioners who understand AI,
                expand scientific knowledge,
                and make the world a better place.
                I sometimes spend ~3 hours per week with each undergrad whom I
                closely mentor.
                Feel free to reach out if you satisfy <i>any</i> of the following
                condition, and I would love to chat about opportunities.

                <ul>
                    <li> Is passionate about NLP.
                        This is usually evidenced by
                        1) taking an NLP class,
                        2) playing around with NLP models on your own, or
                        3)(self-)learning a substantial fraction of material
                        from this
                        <a href="https://docs.google.com/document/d/1D3qmwJWkmYv0h0kqGZyM2umg3AUm2Ji1I1V66QgLa-U/edit">document</a>.
                    </li>
                    <li> Has a strong intellectual interest in social
                        sciences or philosophy.
                    </li>
                    <li> Is from a developing country under-represented in
                        the research community.</li>
                    <li> Excels at competitive programming or math olympiads.</li>
                </ul> -->
                
                Undergrads/grads that I have mentored:
                <ul>
                    <li>Xinyi Han (now Ph.D. at MIT)</li>
                    <li>Yanda Chen (now Ph.D. at Columbia)</li>
                    <li>Charlie Snell (now Ph.D. at UC Berkeley)</li>
                    <li>Dhruba Ghosh (now Ph.D. at University of Washington)</li>
                    <li>Sicheng Tang</li>
                    <li>Kristy Lee (now 5th year Master at UC Berkeley)</li>
                    <li>Zheng Zhang (now 5th year Master at UC Berkeley)</li>
                    <li>Harry Zhao (now 5th year Master at UC Berkeley)</li>
                    <li>Pulkit Bhasin</li>
                    <li>Dong Yang</li>
                    <li>Peter Zhang</li>
                    <li>Oscar Xu (now Ph.D. at University of Pennsylvania)</li>
                    <li>Steve Li</li>
                    <li>JinWoo Ahn</li>
                    <li>Vedant Kumud</li>
                    <li>Heng Wang</li>
                    <li>Anu Soneye</li>
                    <li>Jiaxin Wen</li>
                    <li>Dominic Sobhani</li>
                </ul>

            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Website design from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
